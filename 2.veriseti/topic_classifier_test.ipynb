{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6305a998",
   "metadata": {},
   "source": [
    "# Topic Classifier Test Notebook\n",
    "\n",
    "Bu notebook, önceden eğitilmiş topic classifier modellerini test etmek için kullanılır.\n",
    "\n",
    "## Özellikler:\n",
    "- **Dosyadan Test**: CSV dosyasından test verilerini yükleyebilirsiniz\n",
    "- **Manuel Test**: Kendi yazdığınız metinleri test edebilirsiniz\n",
    "- **Model Karşılaştırması**: Tüm eğitilmiş modelleri karşılaştırabilirsiniz\n",
    "- **Detaylı Analiz**: Confusion matrix ve classification report\n",
    "\n",
    "## Gereksinimler:\n",
    "Eğitim notebook'unun başarıyla çalışmış olması ve aşağıdaki dosyaların `models/` klasöründe bulunması:\n",
    "- `feature_vectorizer.pkl`\n",
    "- `training_config.pkl`\n",
    "- Model dosyaları (örn: `logisticregression_model.pkl`)\n",
    "- `pca_transformer.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174510e",
   "metadata": {},
   "source": [
    "## 1. Kütüphane İmportları ve Konfigürasyon\n",
    "\n",
    "Bu bölüm, training notebook'unda kullanılan tüm sınıfları ve kaydedilen model bileşenlerini yükler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fa5d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kütüphaneler başarıyla yüklendi!\n",
      "Çalışma dizini: c:\\Users\\alper\\OneDrive\\Masaüstü\\dersler\\yap470\\topic_calssifier\\2.veriseti\n",
      "Joblib versiyonu: 1.5.1\n",
      "Python versiyonu: 3.11.9\n",
      "Models klasörü bulundu\n",
      "Mevcut .pkl dosyaları: 11 adet\n",
      "   • feature_vectorizer.pkl\n",
      "   • gradientboosting_model.pkl\n",
      "   • gradientboosting_results.pkl\n",
      "   • logisticregression_model.pkl\n",
      "   • logisticregression_results.pkl\n",
      "   • mlp_model.pkl\n",
      "   • mlp_results.pkl\n",
      "   • pca_transformer.pkl\n",
      "   • svm_model.pkl\n",
      "   • svm_results.pkl\n",
      "   • training_config.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Kütüphaneler başarıyla yüklendi!\")\n",
    "print(f\"Çalışma dizini: {os.getcwd()}\")\n",
    "print(f\"Joblib versiyonu: {joblib.__version__}\")\n",
    "print(f\"Python versiyonu: {sys.version.split()[0]}\")\n",
    "\n",
    "models_dir = \"models\"\n",
    "if os.path.exists(models_dir):\n",
    "    print(f\"Models klasörü bulundu\")\n",
    "    files = [f for f in os.listdir(models_dir) if f.endswith('.pkl')]\n",
    "    print(f\"Mevcut .pkl dosyaları: {len(files)} adet\")\n",
    "    for f in sorted(files):\n",
    "        print(f\"   • {f}\")\n",
    "else:\n",
    "    print(f\"Models klasörü bulunamadı!\")\n",
    "    print(\"Çözüm: Training notebook'unu çalıştırın!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732a4c8",
   "metadata": {},
   "source": [
    "## 2. Training Sınıflarının Tanımlanması\n",
    "\n",
    "**Önemli:** Pickle dosyalarını yükleyebilmek için training notebook'unda kullanılan sınıfların burada da tanımlanması gerekir. Bu sınıflar training'deki aynı yapıdadır.\n",
    "\n",
    "## 2. Kaydedilen Bileşenleri Yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7502eee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm sınıflar tanımlandı!\n",
      "Training notebook'undaki aynı yapılar kullanılıyor\n",
      "Pickle dosyaları yüklenmeye hazır\n"
     ]
    }
   ],
   "source": [
    "# Gerekli sınıf tanımları (pickle yükleme için)\n",
    "from dataclasses import dataclass\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import re\n",
    "import joblib\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING NOTEBOOK'UNDAKI SINIF TANIMLARI\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Training konfigürasyonu - Training notebook'undaki aynı yapı\"\"\"\n",
    "    # Data paths\n",
    "    train_path: str = \"archive/train.csv\"\n",
    "    test_path: str = \"archive/test.csv\"\n",
    "    glove_dir: str = \"glove\"\n",
    "    models_dir: str = \"models\"\n",
    "    cache_dir: str = \"cache\"\n",
    "    \n",
    "    # GloVe settings\n",
    "    glove_dim: int = 100\n",
    "    \n",
    "    # TF-IDF settings\n",
    "    tfidf_max_features: int = 3000\n",
    "    \n",
    "    # KNN settings for missing words\n",
    "    knn_neighbors: int = 5\n",
    "    \n",
    "    # PCA settings\n",
    "    pca_components: int = 100\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_folds: int = 3\n",
    "    \n",
    "    # Random search\n",
    "    random_search_iter: int = 20\n",
    "    random_state: int = 42\n",
    "    \n",
    "    # Strategy settings\n",
    "    use_predefined_params: bool = True\n",
    "    use_hybrid_vectors: bool = True\n",
    "    \n",
    "    # Categories\n",
    "    categories: List[int] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.categories is None:\n",
    "            self.categories = list(range(14))  # 0-13 arası 14 kategori\n",
    "        \n",
    "        # Create directories\n",
    "        os.makedirs(self.models_dir, exist_ok=True)\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "    \n",
    "    @property\n",
    "    def hybrid_vector_dim(self) -> int:\n",
    "        \"\"\"Calculate hybrid vector dimension\"\"\"\n",
    "        if self.use_hybrid_vectors:\n",
    "            return self.glove_dim * len(self.categories)  # 100 * 14 = 1400D\n",
    "        else:\n",
    "            return self.glove_dim\n",
    "\n",
    "class TextPreprocessor:\n",
    "    \"\"\"Text preprocessing utilities - Training'deki aynı yapı\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Advanced text cleaning\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        \n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "        text = re.sub(r'\\b\\w{15,}\\b', '', text)\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "\n",
    "class TFIDFBasedKNNHandler:\n",
    "    \"\"\"TF-IDF based KNN handler for missing words - Training'deki aynı yapı\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_index: Dict, word_score_cache: Dict, config: Config):\n",
    "        self.embeddings_index = embeddings_index\n",
    "        self.word_score_cache = word_score_cache\n",
    "        self.config = config\n",
    "\n",
    "class FeatureVectorizer:\n",
    "    \"\"\"Main feature vectorization class - Training'deki aynı yapı\"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_index: Dict, word_score_cache: Dict, config: Config):\n",
    "        self.embeddings_index = embeddings_index.copy()\n",
    "        self.word_score_cache = word_score_cache\n",
    "        self.config = config\n",
    "        self.missing_word_handler = TFIDFBasedKNNHandler(embeddings_index, word_score_cache, config)\n",
    "        self.missing_word_cache = {}\n",
    "        self.pca = PCA(n_components=config.pca_components, random_state=config.random_state)\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def text_to_vector(self, text: str, target_category: int) -> np.ndarray:\n",
    "        \"\"\"Convert single text to vector\"\"\"\n",
    "        cleaned_text = TextPreprocessor.clean_text(text)\n",
    "        tokens = cleaned_text.split()\n",
    "        stop_words = _stop_words.ENGLISH_STOP_WORDS\n",
    "        filtered_tokens = [t for t in tokens if t not in stop_words and len(t) >= 3]\n",
    "        \n",
    "        if not filtered_tokens:\n",
    "            if self.config.use_hybrid_vectors:\n",
    "                return np.zeros(self.config.hybrid_vector_dim)\n",
    "            else:\n",
    "                return np.zeros(self.config.glove_dim)\n",
    "        \n",
    "        weighted_vectors = []\n",
    "        total_weight = 0\n",
    "        \n",
    "        for token in filtered_tokens:\n",
    "            if token in self.embeddings_index:\n",
    "                base_vector = self.embeddings_index[token]\n",
    "                weight = self._calculate_word_weight(token, target_category)\n",
    "                \n",
    "                if self.config.use_hybrid_vectors:\n",
    "                    hybrid_vector = self._create_hybrid_vector(base_vector, token)\n",
    "                    weighted_vectors.append(hybrid_vector * weight)\n",
    "                else:\n",
    "                    weighted_vectors.append(base_vector * weight)\n",
    "                \n",
    "                total_weight += weight\n",
    "            else:\n",
    "                # Missing word handling\n",
    "                if token in self.missing_word_cache:\n",
    "                    base_vector = self.missing_word_cache[token]\n",
    "                else:\n",
    "                    base_vector = np.random.normal(0, 0.1, size=self.config.glove_dim)\n",
    "                    self.missing_word_cache[token] = base_vector\n",
    "                    self.embeddings_index[token] = base_vector\n",
    "                \n",
    "                if self.config.use_hybrid_vectors:\n",
    "                    hybrid_vector = self._create_hybrid_vector(base_vector, token)\n",
    "                    weighted_vectors.append(hybrid_vector * 0.2)\n",
    "                else:\n",
    "                    weighted_vectors.append(base_vector * 0.2)\n",
    "                \n",
    "                total_weight += 0.2\n",
    "        \n",
    "        if not weighted_vectors or total_weight == 0:\n",
    "            if self.config.use_hybrid_vectors:\n",
    "                return np.zeros(self.config.hybrid_vector_dim)\n",
    "            else:\n",
    "                return np.zeros(self.config.glove_dim)\n",
    "        \n",
    "        return np.sum(weighted_vectors, axis=0) / total_weight\n",
    "    \n",
    "    def _create_hybrid_vector(self, base_vector: np.ndarray, word: str) -> np.ndarray:\n",
    "        \"\"\"Create hybrid vector: 100D GloVe → 1400D (14×TF-IDF weighted)\"\"\"\n",
    "        hybrid_parts = []\n",
    "        \n",
    "        for category in self.config.categories:\n",
    "            tfidf_score = self.word_score_cache.get(word, {}).get(category, 0.0)\n",
    "            category_weighted_vector = base_vector * tfidf_score\n",
    "            hybrid_parts.append(category_weighted_vector)\n",
    "        \n",
    "        return np.concatenate(hybrid_parts)\n",
    "    \n",
    "    def _calculate_word_weight(self, word: str, target_category: int) -> float:\n",
    "        \"\"\"Calculate word weight based on TF-IDF scores\"\"\"\n",
    "        if word not in self.word_score_cache:\n",
    "            return 0.1\n",
    "        \n",
    "        category_scores = [\n",
    "            self.word_score_cache[word].get(cat, 0.0) \n",
    "            for cat in self.config.categories\n",
    "        ]\n",
    "        \n",
    "        target_score = category_scores[target_category]  # 0-indexed kategori\n",
    "        \n",
    "        if target_score <= 0:\n",
    "            return 0.1\n",
    "        \n",
    "        other_scores = [\n",
    "            category_scores[i] for i in range(len(self.config.categories))\n",
    "            if i != target_category\n",
    "        ]\n",
    "        \n",
    "        mean_other = np.mean(other_scores) if other_scores else 0\n",
    "        std_other = np.std(other_scores) if len(other_scores) > 1 else 0.01\n",
    "        \n",
    "        if std_other > 0:\n",
    "            z_score = (target_score - mean_other) / std_other\n",
    "            distinctiveness = max(0, min(2, z_score)) / 2.0\n",
    "        else:\n",
    "            distinctiveness = min(target_score / (mean_other + 0.01), 2.0) / 2.0\n",
    "        \n",
    "        final_weight = target_score * (1.0 + distinctiveness)\n",
    "        return min(final_weight, 2.0)\n",
    "    \n",
    "    def transform_pca(self, vectors: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transform vectors using fitted PCA\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"PCA not fitted yet!\")\n",
    "        return self.pca.transform(vectors)\n",
    "\n",
    "# ============================================================================\n",
    "# MODEL YÜKLEME VE TEST SINIFI\n",
    "# ============================================================================\n",
    "\n",
    "class ModelLoader:\n",
    "    \"\"\"Kaydedilen modelleri ve bileşenleri yüklemek için sınıf\"\"\"\n",
    "    \n",
    "    def __init__(self, models_dir: str = \"models\"):\n",
    "        self.models_dir = models_dir\n",
    "        self.vectorizer = None\n",
    "        self.config = None\n",
    "        self.models = {}\n",
    "        self.category_names = {\n",
    "            0: 'Company', 1: 'Sports', 2: 'Business', 3: 'Science/Tech', \n",
    "            4: 'Politics', 5: 'Education', 6: 'Health', 7: 'Geography',\n",
    "            8: 'Art/Media', 9: 'Nature/Biology', 10: 'Biology', 11: 'Music',\n",
    "            12: 'Film', 13: 'Literature'\n",
    "        }\n",
    "    \n",
    "    def _safe_load_pickle(self, file_path: str):\n",
    "        \"\"\"Güvenli pickle yükleme - hem joblib hem de pickle dener\"\"\"\n",
    "        try:\n",
    "            # Önce joblib ile dene (training'de bu kullanıldı)\n",
    "            obj = joblib.load(file_path)\n",
    "            print(f\"   Joblib ile yüklendi\")\n",
    "            return obj\n",
    "        except Exception as e:\n",
    "            print(f\"   Joblib hatası: {e}\")\n",
    "            try:\n",
    "                # Pickle ile dene\n",
    "                with open(file_path, 'rb') as f:\n",
    "                    obj = pickle.load(f)\n",
    "                print(f\"   Pickle ile yüklendi\")\n",
    "                return obj\n",
    "            except Exception as e2:\n",
    "                print(f\"   Pickle hatası: {e2}\")\n",
    "                raise Exception(f\"Dosya yüklenemedi (joblib: {e}, pickle: {e2})\")\n",
    "    \n",
    "    def load_essential_components(self):\n",
    "        \"\"\"Temel bileşenleri yükle\"\"\"\n",
    "        print(\"\\nTemel bileşenler yükleniyor...\")\n",
    "        \n",
    "        # Models klasörünü kontrol et\n",
    "        if not os.path.exists(self.models_dir):\n",
    "            raise FileNotFoundError(f\"Models klasörü bulunamadı: {self.models_dir}\")\n",
    "        \n",
    "        print(f\"Models klasörü içeriği: {os.listdir(self.models_dir)}\")\n",
    "        \n",
    "        # Config'i yükle\n",
    "        config_path = os.path.join(self.models_dir, \"training_config.pkl\")\n",
    "        if os.path.exists(config_path):\n",
    "            try:\n",
    "                print(f\"Config yükleniyor...\")\n",
    "                self.config = self._safe_load_pickle(config_path)\n",
    "                print(f\"   Hybrid vectors: {self.config.use_hybrid_vectors}\")\n",
    "                print(f\"   Vector dim: {self.config.hybrid_vector_dim}D\")\n",
    "                print(f\"   PCA components: {self.config.pca_components}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Config yükleme hatası: {e}\")\n",
    "                raise Exception(f\"Training config yüklenemedi: {e}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Training config bulunamadı: {config_path}\")\n",
    "        \n",
    "        # FeatureVectorizer'ı yükle\n",
    "        vectorizer_path = os.path.join(self.models_dir, \"feature_vectorizer.pkl\")\n",
    "        if os.path.exists(vectorizer_path):\n",
    "            try:\n",
    "                print(f\"FeatureVectorizer yükleniyor...\")\n",
    "                self.vectorizer = self._safe_load_pickle(vectorizer_path)\n",
    "                print(f\"   PCA fitted: {self.vectorizer.is_fitted}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"FeatureVectorizer yükleme hatası: {e}\")\n",
    "                raise Exception(f\"FeatureVectorizer yüklenemedi: {e}\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"FeatureVectorizer bulunamadı: {vectorizer_path}\")\n",
    "    \n",
    "    def load_available_models(self):\n",
    "        \"\"\"Mevcut modelleri yükle\"\"\"\n",
    "        print(f\"\\nModeller yükleniyor...\")\n",
    "        \n",
    "        model_files = {\n",
    "            'LogisticRegression': 'logisticregression_model.pkl',\n",
    "            'SVM': 'svm_model.pkl', \n",
    "            'MLP': 'mlp_model.pkl',\n",
    "            'GradientBoosting': 'gradientboosting_model.pkl'\n",
    "        }\n",
    "        \n",
    "        loaded_count = 0\n",
    "        for model_name, filename in model_files.items():\n",
    "            model_path = os.path.join(self.models_dir, filename)\n",
    "            if os.path.exists(model_path):\n",
    "                try:\n",
    "                    print(f\"   {model_name} yükleniyor...\")\n",
    "                    model = self._safe_load_pickle(model_path)\n",
    "                    self.models[model_name] = model\n",
    "                    loaded_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"   {model_name} yüklenemedi: {e}\")\n",
    "            else:\n",
    "                print(f\"   {model_name} bulunamadı\")\n",
    "        \n",
    "        if loaded_count == 0:\n",
    "            raise FileNotFoundError(\"Hiçbir model dosyası bulunamadı!\")\n",
    "        \n",
    "        print(f\"\\nToplam {loaded_count} model yüklendi: {list(self.models.keys())}\")\n",
    "    \n",
    "    def predict_single_text(self, text: str, target_category: int, model_name: str = None) -> Dict:\n",
    "        \"\"\"Tek metin için prediction yap\"\"\"\n",
    "        if not self.vectorizer or not self.models:\n",
    "            raise ValueError(\"Bileşenler yüklenmemiş!\")\n",
    "        \n",
    "        # Vektör oluştur\n",
    "        vector = self.vectorizer.text_to_vector(text, target_category)\n",
    "        \n",
    "        results = {}\n",
    "        models_to_test = [model_name] if model_name and model_name in self.models else self.models.keys()\n",
    "        \n",
    "        for name in models_to_test:\n",
    "            try:\n",
    "                model = self.models[name]\n",
    "                \n",
    "                if name == 'LogisticRegression':\n",
    "                    # LogisticRegression full-dimensional (1400D) vektör kullanır\n",
    "                    vector_input = vector.reshape(1, -1)\n",
    "                else:\n",
    "                    # Diğer modeller PCA'lı (100D) vektör kullanır\n",
    "                    vector_input = self.vectorizer.transform_pca(vector.reshape(1, -1))\n",
    "                \n",
    "                prediction = model.predict(vector_input)[0]\n",
    "                results[name] = {\n",
    "                    'prediction': prediction,\n",
    "                    'category_name': self.category_names[prediction]\n",
    "                }\n",
    "            except Exception as e:\n",
    "                results[name] = {'error': str(e)}\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_batch(self, texts: List[str], target_categories: List[int], model_name: str = None) -> Dict:\n",
    "        \"\"\"Toplu prediction\"\"\"\n",
    "        if not self.vectorizer or not self.models:\n",
    "            raise ValueError(\"Bileşenler yüklenmemiş!\")\n",
    "        \n",
    "        # Vektörleri oluştur\n",
    "        vectors = []\n",
    "        for text, target_cat in zip(texts, target_categories):\n",
    "            vector = self.vectorizer.text_to_vector(text, target_cat)\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors_array = np.array(vectors)  # Full-dimensional (1400D)\n",
    "        \n",
    "        # PCA'lı vektörleri hesapla (sadece gerekli modeller varsa)\n",
    "        models_to_process = [model_name] if model_name and model_name in self.models else self.models.keys()\n",
    "        needs_pca = any(name != 'LogisticRegression' for name in models_to_process)\n",
    "        \n",
    "        if needs_pca:\n",
    "            vectors_pca = self.vectorizer.transform_pca(vectors_array)\n",
    "        \n",
    "        # Predictions\n",
    "        results = {}\n",
    "        for name in models_to_process:\n",
    "            try:\n",
    "                model = self.models[name]\n",
    "                \n",
    "                if name == 'LogisticRegression':\n",
    "                    predictions = model.predict(vectors_array)\n",
    "                else:\n",
    "                    predictions = model.predict(vectors_pca)\n",
    "                \n",
    "                results[name] = predictions\n",
    "                \n",
    "            except Exception as e:\n",
    "                results[name] = {'error': str(e)}\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"Tüm sınıflar tanımlandı!\")\n",
    "print(\"Training notebook'undaki aynı yapılar kullanılıyor\")\n",
    "print(\"Pickle dosyaları yüklenmeye hazır\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b05a74",
   "metadata": {},
   "source": [
    "## 3. Bileşenleri Yükle ve CSV Test Verileri Hazırla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae963eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sistem kontrolleri...\n",
      "Çalışma dizini: c:\\Users\\alper\\OneDrive\\Masaüstü\\dersler\\yap470\\topic_calssifier\\2.veriseti\n",
      "Python versiyonu: 3.11.9\n",
      "Models klasörü bulundu\n",
      "Mevcut .pkl dosyaları (11 adet):\n",
      "   • feature_vectorizer.pkl (623.8 MB)\n",
      "   • gradientboosting_model.pkl (0.7 MB)\n",
      "   • gradientboosting_results.pkl (0.3 MB)\n",
      "   • logisticregression_model.pkl (0.2 MB)\n",
      "   • logisticregression_results.pkl (0.3 MB)\n",
      "   • mlp_model.pkl (0.2 MB)\n",
      "   • mlp_results.pkl (0.3 MB)\n",
      "   • pca_transformer.pkl (1.1 MB)\n",
      "   • svm_model.pkl (16.0 MB)\n",
      "   • svm_results.pkl (0.3 MB)\n",
      "   • training_config.pkl (0.0 MB)\n",
      "\n",
      "============================================================\n",
      "BILEŞEN YÜKLEME\n",
      "============================================================\n",
      "\n",
      "Temel bileşenler yükleniyor...\n",
      "Models klasörü içeriği: ['feature_vectorizer.pkl', 'gradientboosting_model.pkl', 'gradientboosting_results.pkl', 'logisticregression_model.pkl', 'logisticregression_results.pkl', 'mlp_model.pkl', 'mlp_results.pkl', 'pca_transformer.pkl', 'svm_model.pkl', 'svm_results.pkl', 'training_config.pkl']\n",
      "Config yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   Hybrid vectors: True\n",
      "   Vector dim: 1400D\n",
      "   PCA components: 100\n",
      "FeatureVectorizer yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   PCA fitted: True\n",
      "\n",
      "Modeller yükleniyor...\n",
      "   LogisticRegression yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   SVM yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   MLP yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   GradientBoosting yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "\n",
      "Toplam 4 model yüklendi: ['LogisticRegression', 'SVM', 'MLP', 'GradientBoosting']\n",
      "\n",
      "TÜM BİLEŞENLER BAŞARIYLA YÜKLENDİ!\n",
      "Vectorizer türü: Hybrid\n",
      "Vector boyutu: 1400D\n",
      "PCA boyutu: 100D\n",
      "Yüklenen modeller: ['LogisticRegression', 'SVM', 'MLP', 'GradientBoosting']\n",
      "\n",
      "============================================================\n",
      "CSV TEST VERİLERİ YÜKLEME\n",
      "============================================================\n",
      "   Joblib ile yüklendi\n",
      "   PCA fitted: True\n",
      "\n",
      "Modeller yükleniyor...\n",
      "   LogisticRegression yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   SVM yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   MLP yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "   GradientBoosting yükleniyor...\n",
      "   Joblib ile yüklendi\n",
      "\n",
      "Toplam 4 model yüklendi: ['LogisticRegression', 'SVM', 'MLP', 'GradientBoosting']\n",
      "\n",
      "TÜM BİLEŞENLER BAŞARIYLA YÜKLENDİ!\n",
      "Vectorizer türü: Hybrid\n",
      "Vector boyutu: 1400D\n",
      "PCA boyutu: 100D\n",
      "Yüklenen modeller: ['LogisticRegression', 'SVM', 'MLP', 'GradientBoosting']\n",
      "\n",
      "============================================================\n",
      "CSV TEST VERİLERİ YÜKLEME\n",
      "============================================================\n",
      "Test dosyası yüklendi: 70000 sample\n",
      "Label dağılımı:\n",
      "   0 (Company): 5000 sample\n",
      "   1 (Sports): 5000 sample\n",
      "   2 (Business): 5000 sample\n",
      "   3 (Science/Tech): 5000 sample\n",
      "   4 (Politics): 5000 sample\n",
      "   5 (Education): 5000 sample\n",
      "   6 (Health): 5000 sample\n",
      "   7 (Geography): 5000 sample\n",
      "   8 (Art/Media): 5000 sample\n",
      "   9 (Nature/Biology): 5000 sample\n",
      "   10 (Biology): 5000 sample\n",
      "   11 (Music): 5000 sample\n",
      "   12 (Film): 5000 sample\n",
      "   13 (Literature): 5000 sample\n",
      "\n",
      "İlk 3 test örneği:\n",
      "1. [Company] TY KU  TY KU /taɪkuː/ is an American alcoholic beverage company that specializes...\n",
      "2. [Company] Odd Lot Entertainment  OddLot Entertainment founded in 2001 by longtime producer...\n",
      "3. [Company] Henkel  Henkel AG & Company KGaA operates worldwide with leading brands and tech...\n",
      "\n",
      "Hızlı performans testi (ilk 50 sample)...\n",
      "Hızlı test sonuçları (50 sample, 0.08s):\n",
      "   LogisticRegression: 1.000 accuracy (627.3 samples/s)\n",
      "   SVM: 1.000 accuracy (627.3 samples/s)\n",
      "   MLP: 1.000 accuracy (627.3 samples/s)\n",
      "   GradientBoosting: 1.000 accuracy (627.3 samples/s)\n",
      "\n",
      "CSV test verileri hazır! Toplam: 70000 sample\n",
      "Test hızı: ~627 samples/s\n",
      "\n",
      "HAZIR! Şimdi manuel test veya detaylı analiz yapabilirsiniz.\n",
      "Test dosyası yüklendi: 70000 sample\n",
      "Label dağılımı:\n",
      "   0 (Company): 5000 sample\n",
      "   1 (Sports): 5000 sample\n",
      "   2 (Business): 5000 sample\n",
      "   3 (Science/Tech): 5000 sample\n",
      "   4 (Politics): 5000 sample\n",
      "   5 (Education): 5000 sample\n",
      "   6 (Health): 5000 sample\n",
      "   7 (Geography): 5000 sample\n",
      "   8 (Art/Media): 5000 sample\n",
      "   9 (Nature/Biology): 5000 sample\n",
      "   10 (Biology): 5000 sample\n",
      "   11 (Music): 5000 sample\n",
      "   12 (Film): 5000 sample\n",
      "   13 (Literature): 5000 sample\n",
      "\n",
      "İlk 3 test örneği:\n",
      "1. [Company] TY KU  TY KU /taɪkuː/ is an American alcoholic beverage company that specializes...\n",
      "2. [Company] Odd Lot Entertainment  OddLot Entertainment founded in 2001 by longtime producer...\n",
      "3. [Company] Henkel  Henkel AG & Company KGaA operates worldwide with leading brands and tech...\n",
      "\n",
      "Hızlı performans testi (ilk 50 sample)...\n",
      "Hızlı test sonuçları (50 sample, 0.08s):\n",
      "   LogisticRegression: 1.000 accuracy (627.3 samples/s)\n",
      "   SVM: 1.000 accuracy (627.3 samples/s)\n",
      "   MLP: 1.000 accuracy (627.3 samples/s)\n",
      "   GradientBoosting: 1.000 accuracy (627.3 samples/s)\n",
      "\n",
      "CSV test verileri hazır! Toplam: 70000 sample\n",
      "Test hızı: ~627 samples/s\n",
      "\n",
      "HAZIR! Şimdi manuel test veya detaylı analiz yapabilirsiniz.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# KAYDEDILEN BİLEŞENLERİ YÜKLE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Sistem kontrolleri...\")\n",
    "print(f\"Çalışma dizini: {os.getcwd()}\")\n",
    "print(f\"Python versiyonu: {sys.version.split()[0]}\")\n",
    "\n",
    "# Models klasörünü kontrol et\n",
    "models_dir = \"models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    print(f\"Models klasörü bulunamadı!\")\n",
    "    print(\"Çözüm: Training notebook'unu çalıştırın!\")\n",
    "    sys.exit()\n",
    "\n",
    "print(f\"Models klasörü bulundu\")\n",
    "pkl_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl')]\n",
    "print(f\"Mevcut .pkl dosyaları ({len(pkl_files)} adet):\")\n",
    "for f in sorted(pkl_files):\n",
    "    size_mb = os.path.getsize(os.path.join(models_dir, f)) / (1024*1024)\n",
    "    print(f\"   • {f} ({size_mb:.1f} MB)\")\n",
    "\n",
    "# ModelLoader'ı başlat ve bileşenleri yükle\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"BILEŞEN YÜKLEME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    loader = ModelLoader(models_dir)\n",
    "    \n",
    "    # Temel bileşenleri yükle\n",
    "    loader.load_essential_components()\n",
    "    \n",
    "    # Modelleri yükle  \n",
    "    loader.load_available_models()\n",
    "    \n",
    "    print(f\"\\nTÜM BİLEŞENLER BAŞARIYLA YÜKLENDİ!\")\n",
    "    print(f\"Vectorizer türü: {'Hybrid' if loader.config.use_hybrid_vectors else 'Standard'}\")\n",
    "    print(f\"Vector boyutu: {loader.config.hybrid_vector_dim}D\")\n",
    "    print(f\"PCA boyutu: {loader.config.pca_components}D\")\n",
    "    print(f\"Yüklenen modeller: {list(loader.models.keys())}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nYÜKLEME HATASI: {e}\")\n",
    "    print(f\"Hata türü: {type(e).__name__}\")\n",
    "    \n",
    "    # Detaylı hata analizi\n",
    "    import traceback\n",
    "    print(f\"\\nDetaylı hata raporu:\")\n",
    "    print(traceback.format_exc())\n",
    "    \n",
    "    print(f\"\\nÇÖZÜMLER:\")\n",
    "    print(\"1. Training notebook'unu (topic_classifier_training.ipynb) çalıştırın\")\n",
    "    print(\"2. Tüm hücreler başarıyla çalıştığından emin olun\")\n",
    "    print(\"3. Models klasöründe gerekli .pkl dosyalarının olduğunu kontrol edin\")\n",
    "    print(\"4. Python sürüm uyumluluğunu kontrol edin\")\n",
    "    sys.exit()\n",
    "\n",
    "# ============================================================================\n",
    "# CSV TEST VERİLERİNİ YÜKLE\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"CSV TEST VERİLERİ YÜKLEME\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_file_path = \"archive/test.csv\"\n",
    "\n",
    "def load_test_data(file_path: str):\n",
    "    \"\"\"Test dosyasını yükle\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, header=None)\n",
    "        df.columns = [\"label\", \"title\", \"description\"]\n",
    "        \n",
    "        # Remove header rows that might contain text values\n",
    "        df = df[df[\"label\"] != \"Class Index\"]\n",
    "        df = df[df[\"label\"] != \"label\"]  # Remove column header if present\n",
    "        \n",
    "        # Remove rows where label is not numeric\n",
    "        df = df[pd.to_numeric(df[\"label\"], errors='coerce').notna()]\n",
    "        df[\"label\"] = df[\"label\"].astype(int)\n",
    "        df[\"text\"] = df[\"title\"] + \" \" + df[\"description\"]\n",
    "        \n",
    "        texts = df[\"text\"].tolist()\n",
    "        labels = df[\"label\"].tolist()\n",
    "        \n",
    "        print(f\"Test dosyası yüklendi: {len(texts)} sample\")\n",
    "        print(f\"Label dağılımı:\")\n",
    "        label_counts = df['label'].value_counts().sort_index()\n",
    "        for label, count in label_counts.items():\n",
    "            print(f\"   {label} ({loader.category_names[label]}): {count} sample\")\n",
    "        \n",
    "        return texts, labels, df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Test dosyası yüklenirken hata: {e}\")\n",
    "        return [], [], pd.DataFrame()\n",
    "\n",
    "if os.path.exists(test_file_path):\n",
    "    test_texts, test_labels, test_df = load_test_data(test_file_path)\n",
    "    \n",
    "    if test_texts:\n",
    "        print(f\"\\nİlk 3 test örneği:\")\n",
    "        for i in range(min(3, len(test_texts))):\n",
    "            print(f\"{i+1}. [{loader.category_names[test_labels[i]]}] {test_texts[i][:80]}...\")\n",
    "            \n",
    "        # Hızlı performans testi (ilk 50 sample)\n",
    "        print(f\"\\nHızlı performans testi (ilk 50 sample)...\")\n",
    "        quick_texts = test_texts[:50]\n",
    "        quick_labels = test_labels[:50]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        quick_results = loader.predict_batch(quick_texts, quick_labels)\n",
    "        test_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"Hızlı test sonuçları ({len(quick_texts)} sample, {test_time:.2f}s):\")\n",
    "        for model_name, predictions in quick_results.items():\n",
    "            if isinstance(predictions, np.ndarray):\n",
    "                accuracy = accuracy_score(quick_labels, predictions)\n",
    "                speed = len(quick_texts) / test_time\n",
    "                print(f\"   {model_name}: {accuracy:.3f} accuracy ({speed:.1f} samples/s)\")\n",
    "            else:\n",
    "                print(f\"   {model_name}: Hata - {predictions.get('error', 'Bilinmeyen')}\")\n",
    "        \n",
    "        print(f\"\\nCSV test verileri hazır! Toplam: {len(test_texts)} sample\")\n",
    "        print(f\"Test hızı: ~{len(quick_texts)/test_time:.0f} samples/s\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Test verileri yüklenemedi!\")\n",
    "        test_texts, test_labels, test_df = [], [], pd.DataFrame()\n",
    "else:\n",
    "    print(f\"Test dosyası bulunamadı: {test_file_path}\")\n",
    "    test_texts, test_labels, test_df = [], [], pd.DataFrame()\n",
    "\n",
    "print(f\"\\nHAZIR! Şimdi manuel test veya detaylı analiz yapabilirsiniz.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad05da",
   "metadata": {},
   "source": [
    "## 4. Manuel Test - Kendi Metninizi Test Edin\n",
    "\n",
    "Bu bölümde kendi yazdığınız metinleri test edebilirsiniz. Aşağıdaki hücreyi düzenleyerek istediğiniz metni ve beklenen kategoriyi belirleyebilirsiniz.\n",
    "\n",
    "**Kategoriler:**\n",
    "- 0: Company (Şirket/Organizasyon)\n",
    "- 1: Sports (Spor)\n",
    "- 2: Business (İş/Ekonomi)\n",
    "- 3: Science/Tech (Bilim/Teknoloji)\n",
    "- 4: Politics (Politika)\n",
    "- 5: Education (Eğitim)\n",
    "- 6: Health (Sağlık)\n",
    "- 7: Geography (Coğrafya)\n",
    "- 8: Art/Media (Sanat/Medya)\n",
    "- 9: Nature/Biology (Doğa/Biyoloji)\n",
    "- 10: Biology (Biyoloji detay)\n",
    "- 11: Music (Müzik)\n",
    "- 12: Film (Film)\n",
    "- 13: Literature (Edebiyat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "177ac319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MANUEL METİN TESTİ\n",
      "============================================================\n",
      "Test Metni: Apple reported record quarterly earnings beating analyst expectations\n",
      "Beklenen Kategori: Business\n",
      "\n",
      "--------------------------------------------------\n",
      "MODEL TAHMİNLERİ:\n",
      "   LogisticRegression: Literature (YANLIŞ)\n",
      "   SVM: Company (YANLIŞ)\n",
      "   MLP: Company (YANLIŞ)\n",
      "   GradientBoosting: Literature (YANLIŞ)\n",
      "\n",
      "Model Consensus: 0/4 (0.0%)\n",
      "Zayıf consensus - Modeller farklı tahminlerde bulunuyor\n",
      "\n",
      "========================================\n",
      "ÖRNEK TESTLER (İsteğe bağlı)\n",
      "========================================\n",
      "\n",
      "1. [Sports] Manchester United won the Champions League final against Rea...\n",
      "   Model tahminleri:\n",
      "     LogisticRegression: Nature/Biology\n",
      "     SVM: Company\n",
      "     MLP: Company\n",
      "     GradientBoosting: Education\n",
      "\n",
      "2. [Science/Tech] NASA successfully launched a new rover to Mars surface...\n",
      "   Model tahminleri:\n",
      "     LogisticRegression: Education\n",
      "     SVM: Education\n",
      "     MLP: Education\n",
      "     GradientBoosting: Education\n",
      "\n",
      "3. [Politics] European Union announces new trade sanctions against Russia...\n",
      "   Model tahminleri:\n",
      "     LogisticRegression: Company\n",
      "     SVM: Company\n",
      "     MLP: Company\n",
      "     GradientBoosting: Company\n"
     ]
    }
   ],
   "source": [
    "# MANUEL TEST - KENDİ METNİNİZİ BURAYA YAZIN\n",
    "print(\"=\"*60)\n",
    "print(\"MANUEL METİN TESTİ\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# BURASI SİZİN DÜZENLEYECEĞINIZ BÖLÜM\n",
    "my_text = \"Apple reported record quarterly earnings beating analyst expectations\"\n",
    "my_expected_category = 2  # 0: Company, 1: Sports, 2: Business, 3: Science/Tech, vs.\n",
    "\n",
    "# Test örnekleri (isterseniz bunları da deneyebilirsiniz)\n",
    "sample_tests = [\n",
    "    (\"Manchester United won the Champions League final against Real Madrid\", 1),\n",
    "    (\"NASA successfully launched a new rover to Mars surface\", 3), \n",
    "    (\"European Union announces new trade sanctions against Russia\", 4),\n",
    "    (\"Tesla stock price surged after strong delivery numbers\", 2),\n",
    "    (\"Scientists discovered a new species of dinosaur in Argentina\", 9),\n",
    "    (\"Harvard University announces new scholarship program\", 5),\n",
    "    (\"WHO reports new breakthrough in cancer treatment\", 6),\n",
    "    (\"Amazon rainforest deforestation reaches record levels\", 9),\n",
    "    (\"Netflix releases new documentary about climate change\", 12),\n",
    "    (\"Beethoven's lost symphony discovered in German archive\", 11)\n",
    "]\n",
    "\n",
    "print(f\"Test Metni: {my_text}\")\n",
    "print(f\"Beklenen Kategori: {loader.category_names[my_expected_category]}\")\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "if my_text and my_text.strip():\n",
    "    # Ana test\n",
    "    results = loader.predict_single_text(my_text, my_expected_category)\n",
    "    \n",
    "    print(\"MODEL TAHMİNLERİ:\")\n",
    "    correct_predictions = 0\n",
    "    total_models = len([r for r in results.values() if 'error' not in r])\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        if 'error' not in result:\n",
    "            prediction = result['prediction']\n",
    "            predicted_category = result['category_name']\n",
    "            is_correct = prediction == my_expected_category\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_predictions += 1\n",
    "                status = \"DOĞRU\"\n",
    "            else:\n",
    "                status = \"YANLIŞ\"\n",
    "            \n",
    "            print(f\"   {model_name}: {predicted_category} ({status})\")\n",
    "        else:\n",
    "            print(f\"   {model_name}: HATA - {result['error']}\")\n",
    "    \n",
    "    if total_models > 0:\n",
    "        consensus_rate = correct_predictions / total_models\n",
    "        print(f\"\\nModel Consensus: {correct_predictions}/{total_models} ({consensus_rate:.1%})\")\n",
    "        \n",
    "        if consensus_rate >= 0.75:\n",
    "            print(\"Güçlü consensus - Modeller genel olarak aynı fikirde!\")\n",
    "        elif consensus_rate >= 0.5:\n",
    "            print(\"Orta consensus - Modeller kısmen hemfikir\")\n",
    "        else:\n",
    "            print(\"Zayıf consensus - Modeller farklı tahminlerde bulunuyor\")\n",
    "\n",
    "    # Örnek testleri de göster\n",
    "    print(f\"\\n\" + \"=\"*40)\n",
    "    print(\"ÖRNEK TESTLER (İsteğe bağlı)\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for i, (sample_text, expected_cat) in enumerate(sample_tests[:3], 1):\n",
    "        print(f\"\\n{i}. [{loader.category_names[expected_cat]}] {sample_text[:60]}...\")\n",
    "        sample_results = loader.predict_single_text(sample_text, expected_cat)\n",
    "        \n",
    "        print(\"   Model tahminleri:\")\n",
    "        for model_name, result in sample_results.items():\n",
    "            if 'error' not in result:\n",
    "                predicted_category = result['category_name']\n",
    "                print(f\"     {model_name}: {predicted_category}\")\n",
    "            else:\n",
    "                print(f\"     {model_name}: HATA\")\n",
    "\n",
    "else:\n",
    "    print(\"Lütfen 'my_text' değişkenini yukarıda düzenleyin!\")\n",
    "    print(\"\\nÖrnek kullanım:\")\n",
    "    print('my_text = \"Your text here...\"')\n",
    "    print('my_expected_category = 1  # Sports kategori için')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659dd087",
   "metadata": {},
   "source": [
    "## 5. Detaylı Analiz - Comprehensive Model Evaluation\n",
    "\n",
    "Bu bölümde tüm modellerin performansını detaylı şekilde analiz ediyoruz:\n",
    "\n",
    "### Analizler:\n",
    "- **Confusion Matrix**: Her model için karışıklık matrisi\n",
    "- **Kategori Bazında Doğruluk**: Hangi kategoride hangi model en başarılı\n",
    "- **Model Hızları**: Prediction süreleri karşılaştırması  \n",
    "- **En İyi Model Seçimi**: Farklı kriterler için öneriler\n",
    "- **Detaylı Performans Metrikleri**: Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881d9646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "COMPREHENSIVE MODEL EVALUATION & ANALYSIS\n",
      "================================================================================\n",
      "Analiz kapsamı: 70000 test sample\n",
      "Test edilen modeller: ['LogisticRegression', 'SVM', 'MLP', 'GradientBoosting']\n",
      "Test verisindeki kategoriler: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "\n",
      "Tüm modellerle test yapılıyor...\n",
      "   LogisticRegression: 70000 prediction in 75.848s\n",
      "   LogisticRegression: 70000 prediction in 75.848s\n",
      "   SVM: 70000 prediction in 109.224s\n",
      "   SVM: 70000 prediction in 109.224s\n",
      "   MLP: 70000 prediction in 80.887s\n",
      "   MLP: 70000 prediction in 80.887s\n",
      "   GradientBoosting: 70000 prediction in 79.323s\n",
      "\n",
      "============================================================\n",
      "1. GENEL PERFORMANS ÖZETİ\n",
      "============================================================\n",
      "             Model Accuracy Speed (samples/s) Time (s)  Correct  Total\n",
      "LogisticRegression   0.9680             922.9   75.848    67757  70000\n",
      "               SVM   0.8810             640.9  109.224    61670  70000\n",
      "               MLP   0.9371             865.4   80.887    65595  70000\n",
      "  GradientBoosting   0.9471             882.5   79.323    66297  70000\n",
      "\n",
      "En yüksek accuracy: LogisticRegression (0.9680)\n",
      "En hızlı model: LogisticRegression (922.9 samples/s)\n",
      "\n",
      "============================================================\n",
      "2. CONFUSION MATRIX ANALİZİ\n",
      "============================================================\n",
      "\n",
      "En iyi model (LogisticRegression) için Confusion Matrix:\n",
      "Confusion Matrix boyutu: (14, 14)\n",
      "Kategori sayısı: 14\n",
      "                Company  Sports  Business  Science/Tech  Politics  Education  \\\n",
      "Company            4757       5        42             4        16         45   \n",
      "Sports               27    4930         4             0         6          4   \n",
      "Business             38       1      4782            36        65         14   \n",
      "Science/Tech          9       3        82          4838        35         15   \n",
      "Politics             11       2        81            26      4821         15   \n",
      "Education            77       6        19             8        13       4793   \n",
      "Health               35       8        20             2         8         30   \n",
      "Geography            17       4         8             4         8         11   \n",
      "Art/Media             0       1         2             0         4          6   \n",
      "Nature/Biology       12       0        28             1        11         14   \n",
      "Biology              25       1        18             2         6          6   \n",
      "Music                10       0        24             1         5          7   \n",
      "Film                 29       0        14             0         4         13   \n",
      "Literature           36       1        57            10         9         20   \n",
      "\n",
      "                Health  Geography  Art/Media  Nature/Biology  Biology  Music  \\\n",
      "Company             37         19          0              35        7      2   \n",
      "Sports              18          2          0               2        3      0   \n",
      "Business            10          7          0              13       10      6   \n",
      "Science/Tech         1          0          0              11        0      1   \n",
      "Politics            10          2          3              18        3      1   \n",
      "Education           15         10          0              29        7      1   \n",
      "Health            4833         16          2              26        3      2   \n",
      "Geography           29       4884          1              26        4      0   \n",
      "Art/Media            2          3       4978               2        2      0   \n",
      "Nature/Biology       2          6          1            4824       92      1   \n",
      "Biology              8          4          0             255     4672      0   \n",
      "Music                0          2          2               9        1   4936   \n",
      "Film                 1          2          2               5        4     11   \n",
      "Literature          11          3          0              26        6      3   \n",
      "\n",
      "                Film  Literature  \n",
      "Company            5          26  \n",
      "Sports             0           4  \n",
      "Business           2          16  \n",
      "Science/Tech       1           4  \n",
      "Politics           2           5  \n",
      "Education          5          17  \n",
      "Health             3          12  \n",
      "Geography          1           3  \n",
      "Art/Media          0           0  \n",
      "Nature/Biology     1           7  \n",
      "Biology            1           2  \n",
      "Music              1           2  \n",
      "Film            4892          23  \n",
      "Literature         1        4817  \n",
      "\n",
      "Confusion Matrix Analizi:\n",
      "   Company: Precision=0.936, Recall=0.951, F1=0.944\n",
      "   Sports: Precision=0.994, Recall=0.986, F1=0.990\n",
      "   Business: Precision=0.923, Recall=0.956, F1=0.939\n",
      "   Science/Tech: Precision=0.981, Recall=0.968, F1=0.974\n",
      "   Politics: Precision=0.962, Recall=0.964, F1=0.963\n",
      "   Education: Precision=0.960, Recall=0.959, F1=0.959\n",
      "   Health: Precision=0.971, Recall=0.967, F1=0.969\n",
      "   Geography: Precision=0.985, Recall=0.977, F1=0.981\n",
      "   Art/Media: Precision=0.998, Recall=0.996, F1=0.997\n",
      "   Nature/Biology: Precision=0.913, Recall=0.965, F1=0.938\n",
      "   Biology: Precision=0.971, Recall=0.934, F1=0.952\n",
      "   Music: Precision=0.994, Recall=0.987, F1=0.991\n",
      "   Film: Precision=0.995, Recall=0.978, F1=0.987\n",
      "   Literature: Precision=0.975, Recall=0.963, F1=0.969\n",
      "\n",
      "============================================================\n",
      "3. KATEGORİ BAZINDA PERFORMANS\n",
      "============================================================\n",
      "\n",
      "Company Kategorisi (5000 sample):\n",
      "   En iyi model: SVM (0.991)\n",
      "   Tüm modeller:\n",
      "     SVM: 0.991\n",
      "     MLP: 0.969\n",
      "     LogisticRegression: 0.951\n",
      "     GradientBoosting: 0.908\n",
      "\n",
      "Sports Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.986)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.986\n",
      "     GradientBoosting: 0.977\n",
      "     MLP: 0.963\n",
      "     SVM: 0.959\n",
      "\n",
      "Business Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.956)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.956\n",
      "     MLP: 0.930\n",
      "     GradientBoosting: 0.905\n",
      "     SVM: 0.813\n",
      "\n",
      "Science/Tech Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.968)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.968\n",
      "     GradientBoosting: 0.956\n",
      "     MLP: 0.934\n",
      "     SVM: 0.836\n",
      "\n",
      "Politics Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.964)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.964\n",
      "     GradientBoosting: 0.936\n",
      "     MLP: 0.927\n",
      "     SVM: 0.810\n",
      "\n",
      "Education Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.959)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.959\n",
      "     GradientBoosting: 0.935\n",
      "     MLP: 0.915\n",
      "     SVM: 0.790\n",
      "\n",
      "Health Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.967)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.967\n",
      "     GradientBoosting: 0.946\n",
      "     MLP: 0.922\n",
      "     SVM: 0.848\n",
      "\n",
      "Geography Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.977)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.977\n",
      "     GradientBoosting: 0.972\n",
      "     MLP: 0.951\n",
      "     SVM: 0.878\n",
      "\n",
      "Art/Media Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.996)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.996\n",
      "     MLP: 0.993\n",
      "     SVM: 0.989\n",
      "     GradientBoosting: 0.989\n",
      "\n",
      "Nature/Biology Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.965)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.965\n",
      "     GradientBoosting: 0.926\n",
      "     MLP: 0.921\n",
      "     SVM: 0.905\n",
      "\n",
      "Biology Kategorisi (5000 sample):\n",
      "   GradientBoosting: 70000 prediction in 79.323s\n",
      "\n",
      "============================================================\n",
      "1. GENEL PERFORMANS ÖZETİ\n",
      "============================================================\n",
      "             Model Accuracy Speed (samples/s) Time (s)  Correct  Total\n",
      "LogisticRegression   0.9680             922.9   75.848    67757  70000\n",
      "               SVM   0.8810             640.9  109.224    61670  70000\n",
      "               MLP   0.9371             865.4   80.887    65595  70000\n",
      "  GradientBoosting   0.9471             882.5   79.323    66297  70000\n",
      "\n",
      "En yüksek accuracy: LogisticRegression (0.9680)\n",
      "En hızlı model: LogisticRegression (922.9 samples/s)\n",
      "\n",
      "============================================================\n",
      "2. CONFUSION MATRIX ANALİZİ\n",
      "============================================================\n",
      "\n",
      "En iyi model (LogisticRegression) için Confusion Matrix:\n",
      "Confusion Matrix boyutu: (14, 14)\n",
      "Kategori sayısı: 14\n",
      "                Company  Sports  Business  Science/Tech  Politics  Education  \\\n",
      "Company            4757       5        42             4        16         45   \n",
      "Sports               27    4930         4             0         6          4   \n",
      "Business             38       1      4782            36        65         14   \n",
      "Science/Tech          9       3        82          4838        35         15   \n",
      "Politics             11       2        81            26      4821         15   \n",
      "Education            77       6        19             8        13       4793   \n",
      "Health               35       8        20             2         8         30   \n",
      "Geography            17       4         8             4         8         11   \n",
      "Art/Media             0       1         2             0         4          6   \n",
      "Nature/Biology       12       0        28             1        11         14   \n",
      "Biology              25       1        18             2         6          6   \n",
      "Music                10       0        24             1         5          7   \n",
      "Film                 29       0        14             0         4         13   \n",
      "Literature           36       1        57            10         9         20   \n",
      "\n",
      "                Health  Geography  Art/Media  Nature/Biology  Biology  Music  \\\n",
      "Company             37         19          0              35        7      2   \n",
      "Sports              18          2          0               2        3      0   \n",
      "Business            10          7          0              13       10      6   \n",
      "Science/Tech         1          0          0              11        0      1   \n",
      "Politics            10          2          3              18        3      1   \n",
      "Education           15         10          0              29        7      1   \n",
      "Health            4833         16          2              26        3      2   \n",
      "Geography           29       4884          1              26        4      0   \n",
      "Art/Media            2          3       4978               2        2      0   \n",
      "Nature/Biology       2          6          1            4824       92      1   \n",
      "Biology              8          4          0             255     4672      0   \n",
      "Music                0          2          2               9        1   4936   \n",
      "Film                 1          2          2               5        4     11   \n",
      "Literature          11          3          0              26        6      3   \n",
      "\n",
      "                Film  Literature  \n",
      "Company            5          26  \n",
      "Sports             0           4  \n",
      "Business           2          16  \n",
      "Science/Tech       1           4  \n",
      "Politics           2           5  \n",
      "Education          5          17  \n",
      "Health             3          12  \n",
      "Geography          1           3  \n",
      "Art/Media          0           0  \n",
      "Nature/Biology     1           7  \n",
      "Biology            1           2  \n",
      "Music              1           2  \n",
      "Film            4892          23  \n",
      "Literature         1        4817  \n",
      "\n",
      "Confusion Matrix Analizi:\n",
      "   Company: Precision=0.936, Recall=0.951, F1=0.944\n",
      "   Sports: Precision=0.994, Recall=0.986, F1=0.990\n",
      "   Business: Precision=0.923, Recall=0.956, F1=0.939\n",
      "   Science/Tech: Precision=0.981, Recall=0.968, F1=0.974\n",
      "   Politics: Precision=0.962, Recall=0.964, F1=0.963\n",
      "   Education: Precision=0.960, Recall=0.959, F1=0.959\n",
      "   Health: Precision=0.971, Recall=0.967, F1=0.969\n",
      "   Geography: Precision=0.985, Recall=0.977, F1=0.981\n",
      "   Art/Media: Precision=0.998, Recall=0.996, F1=0.997\n",
      "   Nature/Biology: Precision=0.913, Recall=0.965, F1=0.938\n",
      "   Biology: Precision=0.971, Recall=0.934, F1=0.952\n",
      "   Music: Precision=0.994, Recall=0.987, F1=0.991\n",
      "   Film: Precision=0.995, Recall=0.978, F1=0.987\n",
      "   Literature: Precision=0.975, Recall=0.963, F1=0.969\n",
      "\n",
      "============================================================\n",
      "3. KATEGORİ BAZINDA PERFORMANS\n",
      "============================================================\n",
      "\n",
      "Company Kategorisi (5000 sample):\n",
      "   En iyi model: SVM (0.991)\n",
      "   Tüm modeller:\n",
      "     SVM: 0.991\n",
      "     MLP: 0.969\n",
      "     LogisticRegression: 0.951\n",
      "     GradientBoosting: 0.908\n",
      "\n",
      "Sports Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.986)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.986\n",
      "     GradientBoosting: 0.977\n",
      "     MLP: 0.963\n",
      "     SVM: 0.959\n",
      "\n",
      "Business Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.956)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.956\n",
      "     MLP: 0.930\n",
      "     GradientBoosting: 0.905\n",
      "     SVM: 0.813\n",
      "\n",
      "Science/Tech Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.968)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.968\n",
      "     GradientBoosting: 0.956\n",
      "     MLP: 0.934\n",
      "     SVM: 0.836\n",
      "\n",
      "Politics Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.964)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.964\n",
      "     GradientBoosting: 0.936\n",
      "     MLP: 0.927\n",
      "     SVM: 0.810\n",
      "\n",
      "Education Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.959)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.959\n",
      "     GradientBoosting: 0.935\n",
      "     MLP: 0.915\n",
      "     SVM: 0.790\n",
      "\n",
      "Health Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.967)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.967\n",
      "     GradientBoosting: 0.946\n",
      "     MLP: 0.922\n",
      "     SVM: 0.848\n",
      "\n",
      "Geography Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.977)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.977\n",
      "     GradientBoosting: 0.972\n",
      "     MLP: 0.951\n",
      "     SVM: 0.878\n",
      "\n",
      "Art/Media Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.996)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.996\n",
      "     MLP: 0.993\n",
      "     SVM: 0.989\n",
      "     GradientBoosting: 0.989\n",
      "\n",
      "Nature/Biology Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.965)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.965\n",
      "     GradientBoosting: 0.926\n",
      "     MLP: 0.921\n",
      "     SVM: 0.905\n",
      "\n",
      "Biology Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.934)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.934\n",
      "     GradientBoosting: 0.902\n",
      "     MLP: 0.816\n",
      "     SVM: 0.745\n",
      "\n",
      "Music Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.987)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.987\n",
      "     GradientBoosting: 0.979\n",
      "     MLP: 0.968\n",
      "     SVM: 0.962\n",
      "\n",
      "Film Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.978)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.978\n",
      "     GradientBoosting: 0.976\n",
      "     MLP: 0.962\n",
      "     SVM: 0.956\n",
      "\n",
      "Literature Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.963)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.963\n",
      "     GradientBoosting: 0.950\n",
      "     MLP: 0.948\n",
      "     SVM: 0.852\n",
      "\n",
      "============================================================\n",
      "4. MODEL KARŞILAŞTIRMA TABLOSU\n",
      "============================================================\n",
      "   En iyi model: LogisticRegression (0.934)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.934\n",
      "     GradientBoosting: 0.902\n",
      "     MLP: 0.816\n",
      "     SVM: 0.745\n",
      "\n",
      "Music Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.987)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.987\n",
      "     GradientBoosting: 0.979\n",
      "     MLP: 0.968\n",
      "     SVM: 0.962\n",
      "\n",
      "Film Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.978)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.978\n",
      "     GradientBoosting: 0.976\n",
      "     MLP: 0.962\n",
      "     SVM: 0.956\n",
      "\n",
      "Literature Kategorisi (5000 sample):\n",
      "   En iyi model: LogisticRegression (0.963)\n",
      "   Tüm modeller:\n",
      "     LogisticRegression: 0.963\n",
      "     GradientBoosting: 0.950\n",
      "     MLP: 0.948\n",
      "     SVM: 0.852\n",
      "\n",
      "============================================================\n",
      "4. MODEL KARŞILAŞTIRMA TABLOSU\n",
      "============================================================\n",
      "             Model Overall Company Sports Business Science/Tech Politics Education Health Geography Art/Media Nature/Biology Biology Music  Film Literature Speed\n",
      "LogisticRegression   0.968   0.951  0.986    0.956        0.968    0.964     0.959  0.967     0.977     0.996          0.965   0.934 0.987 0.978      0.963 922.9\n",
      "               SVM   0.881   0.991  0.959    0.813        0.836    0.810     0.790  0.848     0.878     0.989          0.905   0.745 0.962 0.956      0.852 640.9\n",
      "               MLP   0.937   0.969  0.963    0.930        0.934    0.927     0.915  0.922     0.951     0.993          0.921   0.816 0.968 0.962      0.948 865.4\n",
      "  GradientBoosting   0.947   0.908  0.977    0.905        0.956    0.936     0.935  0.946     0.972     0.989          0.926   0.902 0.979 0.976      0.950 882.5\n",
      "\n",
      "============================================================\n",
      "5. YANLIŞ TAHMİN ANALİZİ\n",
      "============================================================\n",
      "Doğru tahminler: 67757\n",
      "Yanlış tahminler: 2243\n",
      "Genel accuracy: 0.968\n",
      "\n",
      "En sık karışan kategori çiftleri:\n",
      "   Biology → Nature/Biology: 255 kez\n",
      "   Nature/Biology → Biology: 92 kez\n",
      "   Science/Tech → Business: 82 kez\n",
      "   Politics → Business: 81 kez\n",
      "   Education → Company: 77 kez\n",
      "\n",
      "Örnek yanlış tahminler (ilk 5):\n",
      "\n",
      "1. Government of the Democratic Republic of the Congo  The Government of the Democratic Republic of the...\n",
      "   Gerçek: Company | Tahmin: Nature/Biology\n",
      "\n",
      "2. Leopold Bros.  Leopold Bros. is a family-owned and operated distillery located in Denver Colorado....\n",
      "   Gerçek: Company | Tahmin: Health\n",
      "\n",
      "3. Ranik Ultimate Fighting Federation  Ranik Ultimate Fighting Federation (RUFF) is the first Chinese m...\n",
      "   Gerçek: Company | Tahmin: Nature/Biology\n",
      "\n",
      "4. Varèse Sarabande  Varèse Sarabande is an American record label distributed by Universal Music Group ...\n",
      "   Gerçek: Company | Tahmin: Business\n",
      "\n",
      "5. Maine Chance Farm  Maine Chance Farm was an American Thoroughbred horse racing stable in Lexington K...\n",
      "   Gerçek: Company | Tahmin: Geography\n",
      "\n",
      "============================================================\n",
      "6. SONUÇ VE ÖNERİLER\n",
      "============================================================\n",
      "Test sonucu özeti:\n",
      "   • Test edilen sample sayısı: 70000\n",
      "   • Test verisindeki kategoriler: 14 adet\n",
      "   • En iyi genel performans: LogisticRegression (0.9680)\n",
      "   • En hızlı model: LogisticRegression (922.9 samples/s)\n",
      "\n",
      "Kullanım önerileri:\n",
      "   Accuracy öncelikli: LogisticRegression\n",
      "   Hız öncelikli: LogisticRegression\n",
      "   Dengeli seçim: LogisticRegression (accuracy + speed optimized)\n",
      "\n",
      "Analiz tamamlandı! 2025-07-09 01:48:00\n",
      "             Model Overall Company Sports Business Science/Tech Politics Education Health Geography Art/Media Nature/Biology Biology Music  Film Literature Speed\n",
      "LogisticRegression   0.968   0.951  0.986    0.956        0.968    0.964     0.959  0.967     0.977     0.996          0.965   0.934 0.987 0.978      0.963 922.9\n",
      "               SVM   0.881   0.991  0.959    0.813        0.836    0.810     0.790  0.848     0.878     0.989          0.905   0.745 0.962 0.956      0.852 640.9\n",
      "               MLP   0.937   0.969  0.963    0.930        0.934    0.927     0.915  0.922     0.951     0.993          0.921   0.816 0.968 0.962      0.948 865.4\n",
      "  GradientBoosting   0.947   0.908  0.977    0.905        0.956    0.936     0.935  0.946     0.972     0.989          0.926   0.902 0.979 0.976      0.950 882.5\n",
      "\n",
      "============================================================\n",
      "5. YANLIŞ TAHMİN ANALİZİ\n",
      "============================================================\n",
      "Doğru tahminler: 67757\n",
      "Yanlış tahminler: 2243\n",
      "Genel accuracy: 0.968\n",
      "\n",
      "En sık karışan kategori çiftleri:\n",
      "   Biology → Nature/Biology: 255 kez\n",
      "   Nature/Biology → Biology: 92 kez\n",
      "   Science/Tech → Business: 82 kez\n",
      "   Politics → Business: 81 kez\n",
      "   Education → Company: 77 kez\n",
      "\n",
      "Örnek yanlış tahminler (ilk 5):\n",
      "\n",
      "1. Government of the Democratic Republic of the Congo  The Government of the Democratic Republic of the...\n",
      "   Gerçek: Company | Tahmin: Nature/Biology\n",
      "\n",
      "2. Leopold Bros.  Leopold Bros. is a family-owned and operated distillery located in Denver Colorado....\n",
      "   Gerçek: Company | Tahmin: Health\n",
      "\n",
      "3. Ranik Ultimate Fighting Federation  Ranik Ultimate Fighting Federation (RUFF) is the first Chinese m...\n",
      "   Gerçek: Company | Tahmin: Nature/Biology\n",
      "\n",
      "4. Varèse Sarabande  Varèse Sarabande is an American record label distributed by Universal Music Group ...\n",
      "   Gerçek: Company | Tahmin: Business\n",
      "\n",
      "5. Maine Chance Farm  Maine Chance Farm was an American Thoroughbred horse racing stable in Lexington K...\n",
      "   Gerçek: Company | Tahmin: Geography\n",
      "\n",
      "============================================================\n",
      "6. SONUÇ VE ÖNERİLER\n",
      "============================================================\n",
      "Test sonucu özeti:\n",
      "   • Test edilen sample sayısı: 70000\n",
      "   • Test verisindeki kategoriler: 14 adet\n",
      "   • En iyi genel performans: LogisticRegression (0.9680)\n",
      "   • En hızlı model: LogisticRegression (922.9 samples/s)\n",
      "\n",
      "Kullanım önerileri:\n",
      "   Accuracy öncelikli: LogisticRegression\n",
      "   Hız öncelikli: LogisticRegression\n",
      "   Dengeli seçim: LogisticRegression (accuracy + speed optimized)\n",
      "\n",
      "Analiz tamamlandı! 2025-07-09 01:48:00\n"
     ]
    }
   ],
   "source": [
    "# DETAYLI ANALİZ VE MODEL KARŞILAŞTIRMASI\n",
    "# Clear previous outputs to prevent duplication\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Tekrar çalıştırma kontrolü\n",
    "if 'analysis_running' in globals() and analysis_running:\n",
    "    print(\"Analiz zaten çalışıyor! Lütfen bekleyin...\")\n",
    "else:\n",
    "    analysis_running = True\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"COMPREHENSIVE MODEL EVALUATION & ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Önceki analiz değişkenlerini temizle\n",
    "    if 'all_results' in locals():\n",
    "        del all_results\n",
    "    if 'timing_results' in locals():\n",
    "        del timing_results\n",
    "\n",
    "    if not test_texts or not test_labels:\n",
    "        print(\"Test verileri bulunamadı! Önce CSV verilerini yükleyin.\")\n",
    "        analysis_running = False\n",
    "    else:\n",
    "        analysis_size = min(70000, len(test_texts))\n",
    "        analysis_texts = test_texts[:analysis_size]\n",
    "        analysis_labels = test_labels[:analysis_size]\n",
    "        \n",
    "        print(f\"Analiz kapsamı: {analysis_size} test sample\")\n",
    "        print(f\"Test edilen modeller: {list(loader.models.keys())}\")\n",
    "        \n",
    "        # Test verisindeki kategorileri analiz et\n",
    "        unique_labels = sorted(list(set(analysis_labels)))\n",
    "        print(f\"Test verisindeki kategoriler: {unique_labels}\")\n",
    "        \n",
    "        # Tüm modeller için batch prediction ve performans ölçümü\n",
    "        all_results = {}\n",
    "        timing_results = {}\n",
    "        \n",
    "        print(f\"\\nTüm modellerle test yapılıyor...\")\n",
    "        \n",
    "        # Model listesini bir kez al ve tekrarlama engelle\n",
    "        model_list = list(loader.models.keys())\n",
    "        processed_models = set()\n",
    "        \n",
    "        for model_name in model_list:\n",
    "            # Tekrarlama kontrolü\n",
    "            if model_name in processed_models:\n",
    "                continue\n",
    "            processed_models.add(model_name)\n",
    "            \n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                predictions = loader.predict_batch(analysis_texts, analysis_labels, model_name)[model_name]\n",
    "                end_time = time.time()\n",
    "                \n",
    "                if isinstance(predictions, np.ndarray):\n",
    "                    all_results[model_name] = predictions\n",
    "                    timing_results[model_name] = end_time - start_time\n",
    "                    print(f\"   {model_name}: {len(predictions)} prediction in {end_time - start_time:.3f}s\")\n",
    "                else:\n",
    "                    print(f\"   {model_name}: Error - {predictions.get('error', 'Unknown')}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   {model_name}: Exception - {str(e)}\")\n",
    "        \n",
    "        # all_results dict'inin boş olup olmadığını kontrol et\n",
    "        if all_results:\n",
    "            # 1. GENEL PERFORMANS ÖZETİ\n",
    "            print(f\"\\n\" + \"=\"*60)\n",
    "            print(\"1. GENEL PERFORMANS ÖZETİ\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            performance_data = []\n",
    "            \n",
    "            for model_name, predictions in all_results.items():\n",
    "                accuracy = accuracy_score(analysis_labels, predictions)\n",
    "                speed = len(predictions) / timing_results[model_name]\n",
    "                \n",
    "                performance_data.append({\n",
    "                    'Model': model_name,\n",
    "                    'Accuracy': f\"{accuracy:.4f}\",\n",
    "                    'Speed (samples/s)': f\"{speed:.1f}\",\n",
    "                    'Time (s)': f\"{timing_results[model_name]:.3f}\",\n",
    "                    'Correct': sum(predictions == np.array(analysis_labels)),\n",
    "                    'Total': len(analysis_labels)\n",
    "                })\n",
    "            \n",
    "            performance_df = pd.DataFrame(performance_data)\n",
    "            print(performance_df.to_string(index=False))\n",
    "            \n",
    "            # En iyi modelleri belirle\n",
    "            best_accuracy = max(performance_data, key=lambda x: float(x['Accuracy']))\n",
    "            fastest_model = max(performance_data, key=lambda x: float(x['Speed (samples/s)']))\n",
    "            \n",
    "            print(f\"\\nEn yüksek accuracy: {best_accuracy['Model']} ({best_accuracy['Accuracy']})\")\n",
    "            print(f\"En hızlı model: {fastest_model['Model']} ({fastest_model['Speed (samples/s)']} samples/s)\")\n",
    "            \n",
    "            # 2. CONFUSION MATRIX ANALİZİ\n",
    "            print(f\"\\n\" + \"=\"*60)\n",
    "            print(\"2. CONFUSION MATRIX ANALİZİ\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            best_model_name = best_accuracy['Model']\n",
    "            best_predictions = all_results[best_model_name]\n",
    "            \n",
    "            print(f\"\\nEn iyi model ({best_model_name}) için Confusion Matrix:\")\n",
    "            cm = confusion_matrix(analysis_labels, best_predictions)\n",
    "            \n",
    "            # Sadece test verisinde bulunan kategorileri kullan\n",
    "            all_category_names = ['Company', 'Sports', 'Business', 'Science/Tech', 'Politics', \n",
    "                                'Education', 'Health', 'Geography', 'Art/Media', 'Nature/Biology', \n",
    "                                'Biology', 'Music', 'Film', 'Literature']\n",
    "            \n",
    "            # Test verisindeki kategorilerin isimlerini al\n",
    "            present_category_names = [all_category_names[i] for i in unique_labels]\n",
    "            \n",
    "            # Confusion matrix DataFrame'ini oluştur - boyutlar uyumlu olmalı\n",
    "            print(f\"Confusion Matrix boyutu: {cm.shape}\")\n",
    "            print(f\"Kategori sayısı: {len(present_category_names)}\")\n",
    "            \n",
    "            if cm.shape[0] == len(present_category_names):\n",
    "                cm_df = pd.DataFrame(cm, index=present_category_names, columns=present_category_names)\n",
    "                print(cm_df)\n",
    "            else:\n",
    "                print(\"Confusion Matrix:\")\n",
    "                print(cm)\n",
    "                print(f\"Satırlar: {present_category_names}\")\n",
    "                print(f\"Sütunlar: {present_category_names}\")\n",
    "                # Manuel olarak yazdır\n",
    "                print(\"\\nConfusion Matrix (manuel):\")\n",
    "                for i, true_cat in enumerate(present_category_names):\n",
    "                    row_str = f\"{true_cat:12} |\"\n",
    "                    for j in range(cm.shape[1]):\n",
    "                        row_str += f\"{cm[i,j]:6d}\"\n",
    "                    print(row_str)\n",
    "                print(\"             \" + \"\".join([f\"{cat[:6]:>6}\" for cat in present_category_names]))\n",
    "            \n",
    "            # Confusion matrix analizini genişlet\n",
    "            print(f\"\\nConfusion Matrix Analizi:\")\n",
    "            for i, category_idx in enumerate(unique_labels):\n",
    "                category_name = all_category_names[category_idx]\n",
    "                true_positives = cm[i, i]\n",
    "                total_actual = cm[i, :].sum()\n",
    "                total_predicted = cm[:, i].sum()\n",
    "                \n",
    "                if total_actual > 0:\n",
    "                    recall = true_positives / total_actual\n",
    "                    precision = true_positives / total_predicted if total_predicted > 0 else 0\n",
    "                    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "                    \n",
    "                    print(f\"   {category_name}: Precision={precision:.3f}, Recall={recall:.3f}, F1={f1:.3f}\")\n",
    "            \n",
    "            # 3. KATEGORİ BAZINDA PERFORMANS\n",
    "            print(f\"\\n\" + \"=\"*60)\n",
    "            print(\"3. KATEGORİ BAZINDA PERFORMANS\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            category_performance = {}\n",
    "            \n",
    "            for category_idx in unique_labels:\n",
    "                category_name = all_category_names[category_idx]\n",
    "                category_mask = np.array(analysis_labels) == category_idx\n",
    "                category_true = np.array(analysis_labels)[category_mask]\n",
    "                \n",
    "                if sum(category_mask) > 0:  # Sadece var olan kategoriler için\n",
    "                    print(f\"\\n{category_name} Kategorisi ({sum(category_mask)} sample):\")\n",
    "                    \n",
    "                    category_accuracies = []\n",
    "                    \n",
    "                    for model_name, predictions in all_results.items():\n",
    "                        category_pred = predictions[category_mask]\n",
    "                        if len(category_pred) > 0:\n",
    "                            category_acc = accuracy_score(category_true, category_pred)\n",
    "                            category_accuracies.append((model_name, category_acc))\n",
    "                            \n",
    "                    # En iyi modeli bul\n",
    "                    if category_accuracies:\n",
    "                        category_accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "                        best_for_category = category_accuracies[0]\n",
    "                        \n",
    "                        print(f\"   En iyi model: {best_for_category[0]} ({best_for_category[1]:.3f})\")\n",
    "                        print(\"   Tüm modeller:\")\n",
    "                        for model, acc in category_accuracies:\n",
    "                            print(f\"     {model}: {acc:.3f}\")\n",
    "                        \n",
    "                        category_performance[category_name] = category_accuracies\n",
    "            \n",
    "            # 4. MODEL KARŞILAŞTIRMA TABLOSU\n",
    "            print(f\"\\n\" + \"=\"*60)\n",
    "            print(\"4. MODEL KARŞILAŞTIRMA TABLOSU\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            comparison_table = []\n",
    "            \n",
    "            for model_name in all_results.keys():\n",
    "                row = {'Model': model_name}\n",
    "                \n",
    "                # Genel accuracy\n",
    "                overall_acc = accuracy_score(analysis_labels, all_results[model_name])\n",
    "                row['Overall'] = f\"{overall_acc:.3f}\"\n",
    "                \n",
    "                # Kategori bazında accuracy (sadece mevcut kategoriler için)\n",
    "                for category_idx in unique_labels:\n",
    "                    category_name = all_category_names[category_idx]\n",
    "                    category_mask = np.array(analysis_labels) == category_idx\n",
    "                    if sum(category_mask) > 0:\n",
    "                        category_true = np.array(analysis_labels)[category_mask]\n",
    "                        category_pred = all_results[model_name][category_mask]\n",
    "                        category_acc = accuracy_score(category_true, category_pred)\n",
    "                        row[category_name] = f\"{category_acc:.3f}\"\n",
    "                    else:\n",
    "                        row[category_name] = \"N/A\"\n",
    "                \n",
    "                # Hız\n",
    "                row['Speed'] = f\"{len(all_results[model_name]) / timing_results[model_name]:.1f}\"\n",
    "                \n",
    "                comparison_table.append(row)\n",
    "            \n",
    "            comparison_df = pd.DataFrame(comparison_table)\n",
    "            print(comparison_df.to_string(index=False))\n",
    "            \n",
    "            # 5. YANLIŞ TAHMİN ANALİZİ\n",
    "            print(f\"\\n\" + \"=\"*60)\n",
    "            print(\"5. YANLIŞ TAHMİN ANALİZİ\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            # En iyi modelin yanlış tahminlerini analiz et\n",
    "            wrong_predictions = []\n",
    "            correct_count = 0\n",
    "            \n",
    "            for i, (true_label, pred_label) in enumerate(zip(analysis_labels, best_predictions)):\n",
    "                if true_label != pred_label:\n",
    "                    wrong_predictions.append({\n",
    "                        'index': i,\n",
    "                        'text': analysis_texts[i][:100] + \"...\",\n",
    "                        'true': loader.category_names[true_label],\n",
    "                        'predicted': loader.category_names[pred_label],\n",
    "                        'true_idx': true_label,\n",
    "                        'pred_idx': pred_label\n",
    "                    })\n",
    "                else:\n",
    "                    correct_count += 1\n",
    "            \n",
    "            print(f\"Doğru tahminler: {correct_count}\")\n",
    "            print(f\"Yanlış tahminler: {len(wrong_predictions)}\")\n",
    "            print(f\"Genel accuracy: {correct_count / (correct_count + len(wrong_predictions)):.3f}\")\n",
    "            \n",
    "            # En çok karışan kategorileri bul\n",
    "            error_patterns = {}\n",
    "            for wp in wrong_predictions:\n",
    "                pattern = f\"{wp['true']} → {wp['predicted']}\"\n",
    "                error_patterns[pattern] = error_patterns.get(pattern, 0) + 1\n",
    "            \n",
    "            if error_patterns:\n",
    "                print(f\"\\nEn sık karışan kategori çiftleri:\")\n",
    "                sorted_errors = sorted(error_patterns.items(), key=lambda x: x[1], reverse=True)\n",
    "                for pattern, count in sorted_errors[:5]:\n",
    "                    print(f\"   {pattern}: {count} kez\")\n",
    "            \n",
    "            # Örnek yanlış tahminler\n",
    "            if wrong_predictions:\n",
    "                print(f\"\\nÖrnek yanlış tahminler (ilk 5):\")\n",
    "                for i, wp in enumerate(wrong_predictions[:5], 1):\n",
    "                    print(f\"\\n{i}. {wp['text']}\")\n",
    "                    print(f\"   Gerçek: {wp['true']} | Tahmin: {wp['predicted']}\")\n",
    "            \n",
    "            # 6. SONUÇ VE ÖNERİLER\n",
    "            print(f\"\\n\" + \"=\"*60)\n",
    "            print(\"6. SONUÇ VE ÖNERİLER\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            print(f\"Test sonucu özeti:\")\n",
    "            print(f\"   • Test edilen sample sayısı: {analysis_size}\")\n",
    "            print(f\"   • Test verisindeki kategoriler: {len(unique_labels)} adet\")\n",
    "            print(f\"   • En iyi genel performans: {best_accuracy['Model']} ({best_accuracy['Accuracy']})\")\n",
    "            print(f\"   • En hızlı model: {fastest_model['Model']} ({fastest_model['Speed (samples/s)']} samples/s)\")\n",
    "            \n",
    "            print(f\"\\nKullanım önerileri:\")\n",
    "            print(f\"   Accuracy öncelikli: {best_accuracy['Model']}\")\n",
    "            print(f\"   Hız öncelikli: {fastest_model['Model']}\")\n",
    "            \n",
    "            # Dengeli öneri\n",
    "            balanced_scores = []\n",
    "            for perf in performance_data:\n",
    "                # Normalize edilmiş accuracy ve speed skorlarını birleştir\n",
    "                acc_score = float(perf['Accuracy'])\n",
    "                speed_score = min(float(perf['Speed (samples/s)']) / 100, 1.0)  # Normalize\n",
    "                balanced_score = (acc_score * 0.7) + (speed_score * 0.3)  # %70 accuracy, %30 speed\n",
    "                balanced_scores.append((perf['Model'], balanced_score))\n",
    "            \n",
    "            balanced_best = max(balanced_scores, key=lambda x: x[1])\n",
    "            print(f\"   Dengeli seçim: {balanced_best[0]} (accuracy + speed optimized)\")\n",
    "            \n",
    "            print(f\"\\nAnaliz tamamlandı! {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"Hiçbir model çalışmadı! Model yükleme sorunlarını kontrol edin.\")\n",
    "    \n",
    "    # Reset flag\n",
    "    analysis_running = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
